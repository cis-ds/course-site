---
title: "Distributed learning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# cm012 - February 15, 2017

## Overview

* Discuss the need for distributed computing
* Illustrate the split-apply-combine analytical pattern
* Define parallel processing
* Define SQL
* Demonstrate how to access local and remote SQL databases
* Introduce Hadoop and Spark as distributed computing platforms
* Introduce the `sparklyr` package
* Demonstrate how to use `sparklyr` for machine learning using the Titanic data set

## Slides and links

* [Slides](extras/cm012_slides.html)
* [Notes from class](distrib-comp_01.html)

* [The split-apply-combine strategy for data analysis](http://www.jstatsoft.org/v40/i01/paper) - paper by Hadley Wickham establishing a general overview of split-apply-combine problems. Note that the `plyr` package is now deprecated in favor of `dplyr` and the other `tidyverse` packages
* [Accessing databases using `dplyr`](https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html)
* [Taxi dataset](https://cloud.google.com/bigquery/public-data/nyc-tlc-trips)
* [`bigrquery`](https://github.com/rstats-db/bigrquery) - instructions for setting up an account to access Google Bigquery databases
* [`sparklyr`](http://spark.rstudio.com/) - introduction to the `sparklyr` interface for Spark

## To do for Monday

* Work on [homework 7](hw07-resamp-distrib-learn.html)

